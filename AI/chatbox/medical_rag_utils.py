import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import pickle
import json
import os
from datetime import datetime
import re

def load_medical_data():
    """Load medical FAISS index vÃ  chunks data"""
    try:
        # Äáº£m báº£o tÃ¬m file trong thÆ° má»¥c chatbox
        current_dir = os.path.dirname(__file__)
        chunks_file = os.path.join(current_dir, "medical_chunks_with_metadata.pkl")
        index_file = os.path.join(current_dir, "medical_faiss_index.index")
        
        with open(chunks_file, "rb") as f:
            data = pickle.load(f)
        
        # Handle different data formats
        if isinstance(data, dict) and 'chunks' in data:
            chunks_data = data['chunks']
        elif isinstance(data, list):
            chunks_data = data
        else:
            print("âŒ Unknown chunks data format")
            return None, None, None
        
        index = faiss.read_index(index_file)
        
        # Load embedder - sá»­ dá»¥ng all-MiniLM-L6-v2 Ä‘á»ƒ match vá»›i FAISS index hiá»‡n táº¡i
        try:
            embedder = SentenceTransformer('all-MiniLM-L6-v2')
            print("âœ… Using model: all-MiniLM-L6-v2 (compatible with existing FAISS index)")
        except Exception as model_error:
            print(f"âŒ Cannot load embedding model: {model_error}")
            return None, None, None
        
        return index, chunks_data, embedder
    except FileNotFoundError:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y medical data files. Vui lÃ²ng cháº¡y setup_icd_rag.py trÆ°á»›c.")
        return None, None, None
    except Exception as e:
        print(f"âŒ Lá»—i khi load medical data: {e}")
        return None, None, None

def improve_vietnamese_query(query):
    """Cáº£i thiá»‡n query tiáº¿ng Viá»‡t báº±ng cÃ¡ch thÃªm keywords tiáº¿ng Anh"""
    
    # Dictionary dá»‹ch cÃ¡c tá»« y táº¿ phá»• biáº¿n
    medical_translations = {
        # Triá»‡u chá»©ng
        "Ä‘au Ä‘áº§u": "headache head pain",
        "buá»“n nÃ´n": "nausea vomiting", 
        "sá»‘t cao": "high fever temperature",
        "ho": "cough coughing",
        "Ä‘au ngá»±c": "chest pain",
        "khÃ³ thá»Ÿ": "difficulty breathing dyspnea",
        "Ä‘au dáº¡ dÃ y": "stomach pain gastric pain",
        
        # Bá»‡nh
        "tiá»ƒu Ä‘Æ°á»ng": "diabetes mellitus",
        "cao huyáº¿t Ã¡p": "hypertension high blood pressure",
        "viÃªm phá»•i": "pneumonia lung inflammation",
        "ung thÆ° phá»•i": "lung cancer pulmonary cancer",
        "viÃªm gan": "hepatitis liver inflammation",
        "Ä‘au tim": "heart pain cardiac pain",
        
        # Bá»™ pháº­n cÆ¡ thá»ƒ
        "phá»•i": "lung pulmonary",
        "tim": "heart cardiac",
        "gan": "liver hepatic",
        "dáº¡ dÃ y": "stomach gastric",
        "tháº­n": "kidney renal",
        "nÃ£o": "brain cerebral"
    }
    
    enhanced_query = query.lower()
    
    # ThÃªm tá»« tiáº¿ng Anh tÆ°Æ¡ng á»©ng
    for vietnamese, english in medical_translations.items():
        if vietnamese in enhanced_query:
            enhanced_query += f" {english}"
    
    return enhanced_query

def search_medical_symptoms_and_diseases(query, top_k=5, filters=None):
    """
    TÃ¬m kiáº¿m cÃ¡c triá»‡u chá»©ng vÃ  bá»‡nh táº­t tá»« medical knowledge base vá»›i improved search
    
    Args:
        query: CÃ¢u há»i hoáº·c mÃ´ táº£ triá»‡u chá»©ng cá»§a ngÆ°á»i dÃ¹ng
        top_k: Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
        filters: Bá»™ lá»c tÃ¬m kiáº¿m (category_id, entity_type, etc.)
    """
    index, chunks_data, embedder = load_medical_data()
    
    if not index or not chunks_data or not embedder:
        return []
    
    try:
        # Táº¡o query embedding
        # Cáº£i thiá»‡n query vá»›i Vietnamese enhancement
        enhanced_query = improve_vietnamese_query(query)
        
        # Táº¡o embedding cho enhanced query
        query_embedding = embedder.encode([enhanced_query], convert_to_numpy=True)
        
        # TÃ¬m kiáº¿m trong FAISS (láº¥y nhiá»u hÆ¡n Ä‘á»ƒ filter)
        search_size = min(top_k * 5, len(chunks_data))
        distances, indices = index.search(query_embedding, search_size)
        
        results = []
        seen_entities = set()  # TrÃ¡nh duplicate entities
        
        for i, idx in enumerate(indices[0]):
            chunk_data = chunks_data[idx]
            metadata = chunk_data['metadata']
            
            # Ãp dá»¥ng filters náº¿u cÃ³
            if filters:
                skip = False
                for key, value in filters.items():
                    if key == 'category_id':
                        if isinstance(value, list):
                            if metadata.get('category_id') not in value:
                                skip = True
                                break
                        else:
                            if metadata.get('category_id') != value:
                                skip = True
                                break
                    elif key == 'entity_type' and metadata.get('entity_type') != value:
                        skip = True
                        break
                    elif key == 'has_icd_code' and value and not metadata.get('icd_code'):
                        skip = True
                        break
                    elif key == 'source_type' and metadata.get('source_type') != value:
                        skip = True
                        break
                
                if skip:
                    continue
            
            # TrÃ¡nh duplicate entities (trá»« khi lÃ  category)
            entity_identifier = f"{metadata.get('entity_name', '')}-{metadata.get('icd_code', '')}"
            if entity_identifier in seen_entities and metadata.get('source_type') != 'icd_category':
                continue
            seen_entities.add(entity_identifier)
            
            # TÃ­nh relevance score vá»›i boost cho medical relevance
            base_score = 1 / (1 + distances[0][i])
            
            # Boost score based on medical relevance
            boost_factor = 1.0
            
            # Boost cho entities cÃ³ ICD code
            if metadata.get('icd_code'):
                boost_factor *= 1.2
            
            # Boost cho diseases/conditions
            if metadata.get('entity_type') == 'disease_condition':
                boost_factor *= 1.1
            
            # Boost cho categories liÃªn quan Ä‘áº¿n triá»‡u chá»©ng
            if metadata.get('category_id') in ['0M']:  # Symptoms, signs or clinical findings
                boost_factor *= 1.3
            
            final_score = base_score * boost_factor
            
            results.append({
                'text': chunk_data['text'],
                'metadata': metadata,
                'distance': distances[0][i],
                'relevance_score': final_score
            })
            
            if len(results) >= top_k:
                break
        
        # Sort by final relevance score
        results.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        return results[:top_k]
        
    except Exception as e:
        print(f"âŒ Lá»—i khi tÃ¬m kiáº¿m medical data: {e}")
        import traceback
        traceback.print_exc()
        return []




def create_medical_diagnostic_context(search_results, user_symptoms=""):
    """
    Táº¡o context cho cháº©n Ä‘oÃ¡n y táº¿ tá»« search results
    
    Args:
        search_results: Káº¿t quáº£ tÃ¬m kiáº¿m tá»« medical knowledge base
        user_symptoms: Triá»‡u chá»©ng mÃ  user mÃ´ táº£
    """
    if not search_results:
        return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin y táº¿ liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."
    
    context_parts = []
    
    # ThÃªm thÃ´ng tin vá» triá»‡u chá»©ng user mÃ´ táº£
    if user_symptoms:
        context_parts.append(f"=== TRIá»†U CHá»¨NG NGÆ¯á»œI DÃ™NG MÃ” Táº¢ ===")
        context_parts.append(f"MÃ´ táº£: {user_symptoms}")
        context_parts.append("")
    
    # PhÃ¢n loáº¡i results theo loáº¡i
    symptoms_results = []
    diseases_results = []
    categories_results = []
    
    for result in search_results:
        metadata = result['metadata']
        if metadata.get('category_id') == '0M':  # Symptoms category
            symptoms_results.append(result)
        elif metadata.get('source_type') == 'icd_category':
            categories_results.append(result)
        else:
            diseases_results.append(result)
    
    # Hiá»ƒn thá»‹ triá»‡u chá»©ng liÃªn quan
    if symptoms_results:
        context_parts.append("=== TRIá»†U CHá»¨NG VÃ€ Dáº¤U HIá»†U LIÃŠN QUAN ===")
        for i, result in enumerate(symptoms_results, 1):
            metadata = result['metadata']
            
            context_parts.append(f"Triá»‡u chá»©ng {i}:")
            if metadata.get('entity_name'):
                context_parts.append(f"- TÃªn: {metadata['entity_name']}")
            if metadata.get('icd_code'):
                context_parts.append(f"- MÃ£ ICD-11: {metadata['icd_code']}")
            
            # Láº¥y pháº§n definition tá»« text
            text_lines = result['text'].split('\n')
            for line in text_lines:
                if 'Äá»‹nh nghÄ©a:' in line or 'Äá»‹nh nghÄ©a chi tiáº¿t:' in line:
                    context_parts.append(f"- {line}")
                    break
            
            context_parts.append(f"- Äá»™ liÃªn quan: {result['relevance_score']:.3f}")
            context_parts.append("")
    
    # Hiá»ƒn thá»‹ cÃ¡c bá»‡nh cÃ³ thá»ƒ liÃªn quan
    if diseases_results:
        context_parts.append("=== CÃC Bá»†NH CÃ“ THá»‚ LIÃŠN QUAN ===")
        for i, result in enumerate(diseases_results, 1):
            metadata = result['metadata']
            
            context_parts.append(f"Bá»‡nh {i}:")
            if metadata.get('entity_name'):
                context_parts.append(f"- TÃªn bá»‡nh: {metadata['entity_name']}")
            if metadata.get('icd_code'):
                context_parts.append(f"- MÃ£ ICD-11: {metadata['icd_code']}")
            if metadata.get('category_name'):
                context_parts.append(f"- Danh má»¥c: {metadata['category_name']}")
            
            # Láº¥y thÃ´ng tin quan trá»ng tá»« text
            text_lines = result['text'].split('\n')
            for line in text_lines:
                if any(keyword in line for keyword in ['Äá»‹nh nghÄ©a:', 'Bao gá»“m:', 'Triá»‡u chá»©ng:']):
                    context_parts.append(f"- {line}")
                    if len([l for l in context_parts if f"Bá»‡nh {i}:" in l or l.startswith("- ")]) > 6:
                        break
            
            context_parts.append(f"- Äá»™ liÃªn quan: {result['relevance_score']:.3f}")
            context_parts.append("")
    
    # Hiá»ƒn thá»‹ thÃ´ng tin category náº¿u cÃ³
    if categories_results:
        context_parts.append("=== DANH Má»¤C Y Táº¾ LIÃŠN QUAN ===")
        for i, result in enumerate(categories_results, 1):
            metadata = result['metadata']
            
            if metadata.get('category_name'):
                context_parts.append(f"Danh má»¥c {i}: {metadata['category_name']}")
                if metadata.get('category_id'):
                    context_parts.append(f"- MÃ£ danh má»¥c: {metadata['category_id']}")
                
                # Láº¥y definition tá»« text
                text_lines = result['text'].split('\n')
                for line in text_lines:
                    if 'Äá»‹nh nghÄ©a:' in line:
                        context_parts.append(f"- {line}")
                        break
                
                context_parts.append("")
    
    return "\n".join(context_parts)

def create_medical_consultation_context(search_results, consultation_type="general"):
    """
    Táº¡o context cho tÆ° váº¥n y táº¿
    
    Args:
        search_results: Káº¿t quáº£ tÃ¬m kiáº¿m
        consultation_type: Loáº¡i tÆ° váº¥n (general, emergency, prevention, etc.)
    """
    if not search_results:
        return "KhÃ´ng cÃ³ thÃ´ng tin y táº¿ liÃªn quan Ä‘Æ°á»£c tÃ¬m tháº¥y."
    
    context_parts = []
    context_parts.append("=== THÃ”NG TIN Y Táº¾ TÃŒM ÄÆ¯á»¢C ===")
    
    for i, result in enumerate(search_results, 1):
        metadata = result['metadata']
        text = result['text']
        
        context_parts.append(f"\n--- ThÃ´ng tin {i} ---")
        
        # ThÃ´ng tin cÆ¡ báº£n
        if metadata.get('entity_name'):
            context_parts.append(f"TÃªn: {metadata['entity_name']}")
        
        if metadata.get('icd_code'):
            context_parts.append(f"MÃ£ ICD-11: {metadata['icd_code']}")
        
        if metadata.get('category_name'):
            context_parts.append(f"Danh má»¥c: {metadata['category_name']}")
        
        # TrÃ­ch xuáº¥t thÃ´ng tin quan trá»ng tá»« text
        text_lines = text.split('\n')
        important_info = []
        
        for line in text_lines:
            if any(keyword in line for keyword in [
                'Äá»‹nh nghÄ©a:', 'Äá»‹nh nghÄ©a chi tiáº¿t:', 'Bao gá»“m:', 
                'Loáº¡i trá»«:', 'Tá»« Ä‘á»“ng nghÄ©a:', 'Triá»‡u chá»©ng:'
            ]):
                important_info.append(line)
        
        if important_info:
            context_parts.append("ThÃ´ng tin chi tiáº¿t:")
            for info in important_info[:3]:  # Giá»›i háº¡n 3 dÃ²ng Ä‘á»ƒ trÃ¡nh quÃ¡ dÃ i
                context_parts.append(f"  {info}")
        
        context_parts.append(f"Äá»™ liÃªn quan: {result['relevance_score']:.3f}")
    
    # ThÃªm disclaimer cho tÆ° váº¥n y táº¿
    context_parts.append("\n=== LÆ¯U Ã QUAN TRá»ŒNG ===")
    context_parts.append("- ThÃ´ng tin trÃªn chá»‰ mang tÃ­nh cháº¥t tham kháº£o")
    context_parts.append("- KhÃ´ng thay tháº¿ cho cháº©n Ä‘oÃ¡n vÃ  Ä‘iá»u trá»‹ cá»§a bÃ¡c sÄ©")
    context_parts.append("- Náº¿u cÃ³ triá»‡u chá»©ng nghiÃªm trá»ng, hÃ£y Ä‘áº¿n cÆ¡ sá»Ÿ y táº¿ ngay láº­p tá»©c")
    
    return "\n".join(context_parts)

def get_medical_statistics():
    """Láº¥y thá»‘ng kÃª vá» medical knowledge base"""
    try:
        # Äáº£m báº£o tÃ¬m file trong thÆ° má»¥c chatbox
        current_dir = os.path.dirname(__file__)
        chunks_file = os.path.join(current_dir, "medical_chunks_with_metadata.pkl")
        
        with open(chunks_file, "rb") as f:
            chunks_data = pickle.load(f)
        
        metadata_list = chunks_data.get('metadata', [])
        
        stats = {
            'total_chunks': len(metadata_list),
            'total_categories': chunks_data.get('total_categories', 0),
            'categories': {},
            'entity_types': {},
            'has_icd_code': 0,
            'created_at': chunks_data.get('created_at'),
            'data_source': chunks_data.get('data_source', 'unknown')
        }
        
        # Thá»‘ng kÃª chi tiáº¿t
        for metadata in metadata_list:
            # Category stats
            category_id = metadata.get('category_id')
            category_name = metadata.get('category_name')
            if category_id:
                if category_id not in stats['categories']:
                    stats['categories'][category_id] = {
                        'name': category_name,
                        'count': 0
                    }
                stats['categories'][category_id]['count'] += 1
            
            # Entity type stats
            entity_type = metadata.get('entity_type', 'unknown')
            stats['entity_types'][entity_type] = stats['entity_types'].get(entity_type, 0) + 1
            
            # ICD code stats
            if metadata.get('icd_code'):
                stats['has_icd_code'] += 1
        
        return stats
        
    except FileNotFoundError:
        return {"error": "Medical data not found. Please run setup_icd_rag.py first."}
    except Exception as e:
        return {"error": f"Error getting medical statistics: {str(e)}"}

def classify_medical_query_intent(query):
    """
    PhÃ¢n loáº¡i intent cá»§a cÃ¢u há»i y táº¿
    
    Returns:
        - symptom_inquiry: Há»i vá» triá»‡u chá»©ng
        - disease_inquiry: Há»i vá» bá»‡nh táº­t
        - treatment_inquiry: Há»i vá» Ä‘iá»u trá»‹
        - prevention_inquiry: Há»i vá» phÃ²ng ngá»«a
        - general_medical: CÃ¢u há»i y táº¿ chung
        - emergency: TÃ¬nh huá»‘ng kháº©n cáº¥p
    """
    query_lower = query.lower()
    
    # Tá»« khÃ³a triá»‡u chá»©ng
    symptom_keywords = [
        'triá»‡u chá»©ng', 'dáº¥u hiá»‡u', 'biá»ƒu hiá»‡n', 'Ä‘au', 'sá»‘t', 'ho', 'khÃ³ thá»Ÿ',
        'buá»“n nÃ´n', 'nÃ´n má»­a', 'tiÃªu cháº£y', 'tÃ¡o bÃ³n', 'chÃ³ng máº·t', 'Ä‘au Ä‘áº§u',
        'má»‡t má»i', 'ngá»©a', 'phÃ¡t ban', 'sÆ°ng', 'tÃª', 'táº¡i sao', 'vÃ¬ sao',
        'bá»‹', 'cÃ³', 'xuáº¥t hiá»‡n', 'cáº£m tháº¥y'
    ]
    
    # Tá»« khÃ³a bá»‡nh táº­t
    disease_keywords = [
        'bá»‡nh', 'chá»©ng', 'há»™i chá»©ng', 'rá»‘i loáº¡n', 'viÃªm', 'nhiá»…m trÃ¹ng',
        'ung thÆ°', 'tim máº¡ch', 'tiá»ƒu Ä‘Æ°á»ng', 'cao huyáº¿t Ã¡p', 'Ä‘á»™t quá»µ',
        'gÃ¬ lÃ ', 'lÃ  gÃ¬', 'Ä‘á»‹nh nghÄ©a', 'nguyÃªn nhÃ¢n'
    ]
    
    # Tá»« khÃ³a Ä‘iá»u trá»‹
    treatment_keywords = [
        'Ä‘iá»u trá»‹', 'chá»¯a', 'thuá»‘c', 'uá»‘ng thuá»‘c', 'chá»¯a trá»‹', 'há»— trá»£',
        'pháº«u thuáº­t', 'thá»§ thuáº­t', 'lÃ m sao', 'cÃ¡ch nÃ o', 'phÆ°Æ¡ng phÃ¡p'
    ]
    
    # Tá»« khÃ³a phÃ²ng ngá»«a
    prevention_keywords = [
        'phÃ²ng ngá»«a', 'phÃ²ng trÃ¡nh', 'ngÄƒn ngá»«a', 'dá»± phÃ²ng', 'trÃ¡nh',
        'lÃ m gÃ¬ Ä‘á»ƒ khÃ´ng', 'cÃ¡ch phÃ²ng', 'báº£o vá»‡'
    ]
    
    # Tá»« khÃ³a kháº©n cáº¥p
    emergency_keywords = [
        'cáº¥p cá»©u', 'kháº©n cáº¥p', 'nguy hiá»ƒm', 'nghiÃªm trá»ng', 'gáº¥p',
        'ngay láº­p tá»©c', 'bÃ¡o Ä‘á»™ng', 'Ä‘au dá»¯ dá»™i', 'khÃ´ng thá»Ÿ Ä‘Æ°á»£c',
        'báº¥t tá»‰nh', 'ngáº¥t', 'co giáº­t'
    ]
    
    # Äáº¿m sá»‘ tá»« khÃ³a phÃ¹ há»£p
    symptom_count = sum(1 for keyword in symptom_keywords if keyword in query_lower)
    disease_count = sum(1 for keyword in disease_keywords if keyword in query_lower)
    treatment_count = sum(1 for keyword in treatment_keywords if keyword in query_lower)
    prevention_count = sum(1 for keyword in prevention_keywords if keyword in query_lower)
    emergency_count = sum(1 for keyword in emergency_keywords if keyword in query_lower)
    
    # Æ¯u tiÃªn emergency trÆ°á»›c
    if emergency_count > 0:
        return "emergency"
    
    # Sau Ä‘Ã³ phÃ¢n loáº¡i theo sá»‘ lÆ°á»£ng tá»« khÃ³a
    max_count = max(symptom_count, disease_count, treatment_count, prevention_count)
    
    if max_count == 0:
        return "general_medical"
    elif symptom_count == max_count:
        return "symptom_inquiry"
    elif disease_count == max_count:
        return "disease_inquiry"
    elif treatment_count == max_count:
        return "treatment_inquiry"
    elif prevention_count == max_count:
        return "prevention_inquiry"
    else:
        return "general_medical"

# Test functions
def test_medical_search():
    """Test function Ä‘á»ƒ kiá»ƒm tra medical search"""
    test_queries = [
        "Ä‘au Ä‘áº§u vÃ  chÃ³ng máº·t",
        "sá»‘t cao vÃ  ho",
        "Ä‘au bá»¥ng vÃ  tiÃªu cháº£y",
        "khÃ³ thá»Ÿ vÃ  Ä‘au ngá»±c",
        "má»‡t má»i vÃ  sá»¥t cÃ¢n"
    ]
    
    print("ğŸ§ª Testing Medical Search...")
    
    for query in test_queries:
        print(f"\nğŸ” Query: '{query}'")
        intent = classify_medical_query_intent(query)
        print(f"Intent: {intent}")
        
        results = search_medical_symptoms_and_diseases(query, top_k=3)
        if results:
            print("Top results:")
            for i, result in enumerate(results, 1):
                metadata = result['metadata']
                entity_name = metadata.get('entity_name', 'Unknown')
                icd_code = metadata.get('icd_code', 'N/A')
                relevance = result['relevance_score']
                print(f"  {i}. {entity_name} (ICD: {icd_code}) - Relevance: {relevance:.3f}")
        else:
            print("  No results found")

if __name__ == "__main__":
    # Test medical search functionality
    test_medical_search()
    
    # Display statistics
    print(f"\nğŸ“Š Medical Knowledge Base Statistics:")
    stats = get_medical_statistics()
    if 'error' not in stats:
        print(f"Total chunks: {stats['total_chunks']}")
        print(f"Total categories: {stats['total_categories']}")
        print(f"Chunks with ICD codes: {stats['has_icd_code']}")
        print(f"Data source: {stats['data_source']}")
        print(f"Created at: {stats['created_at']}")
    else:
        print(f"Error: {stats['error']}")
