from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
from config import init_app_context, DB_CONFIG, client, APP_CONTEXT
import uuid
from collections import deque

from medical_rag_utils import (
    search_medical_symptoms_and_diseases,
    search_symptoms_only,
    search_diseases_only,
    create_medical_diagnostic_context,
    create_medical_consultation_context,
    classify_medical_query_intent,
    get_medical_statistics
)
from hybrid_search import get_hybrid_search_engine
from query_transformation import transform_medical_query
from structured_extraction import extract_medical_structure
from medical_logging import log_query, log_search, log_llm, log_extraction, log_error, get_stats
import time
import json
from datetime import datetime, timedelta

app = Flask(__name__)
CORS(app, origins=['http://localhost:5173'])

# Kh·ªüi t·∫°o ·ª©ng d·ª•ng
init_app_context(app)

# Bi·∫øn to√†n c·ª•c
answer_cache = {}

conversation_sessions = {}  # {session_id: {"history": deque, "last_activity": datetime}}
MAX_HISTORY_LENGTH = 20     # Gi·ªõi h·∫°n s·ªë tin nh·∫Øn trong l·ªãch s·ª≠
SESSION_TIMEOUT = 30 * 60   # 30 ph√∫t timeout

# Th√™m h√†m helper ƒë·ªÉ qu·∫£n l√Ω session
def get_or_create_session(session_id=None):
    """L·∫•y ho·∫∑c t·∫°o session m·ªõi"""
    if not session_id:
        session_id = str(uuid.uuid4())
    
    current_time = datetime.now()
    
    # L√†m s·∫°ch c√°c session h·∫øt h·∫°n
    expired_sessions = []
    for sid, session_data in conversation_sessions.items():
        if (current_time - session_data["last_activity"]).seconds > SESSION_TIMEOUT:
            expired_sessions.append(sid)
    
    for sid in expired_sessions:
        del conversation_sessions[sid]
    
    # T·∫°o session m·ªõi n·∫øu ch∆∞a t·ªìn t·∫°i
    if session_id not in conversation_sessions:
        conversation_sessions[session_id] = {
            "history": deque(maxlen=MAX_HISTORY_LENGTH),
            "last_activity": current_time
        }
    else:
        conversation_sessions[session_id]["last_activity"] = current_time
    
    return session_id

def add_to_conversation_history(session_id, role, content):
    """Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    if session_id in conversation_sessions:
        conversation_sessions[session_id]["history"].append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

def get_conversation_context(session_id, max_messages=10):
    """L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i g·∫ßn ƒë√¢y"""
    if session_id not in conversation_sessions:
        return []
    
    history = list(conversation_sessions[session_id]["history"])
    # L·∫•y max_messages tin nh·∫Øn g·∫ßn nh·∫•t
    recent_history = history[-max_messages:] if len(history) > max_messages else history
    
    # Chuy·ªÉn ƒë·ªïi format cho OpenAI API
    context_messages = []
    for msg in recent_history:
        context_messages.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    return context_messages

@app.route('/ask', methods=['POST'])
def ask():
    user_query = request.json['query']
    session_id = request.json.get('session_id')  # Th√™m session_id t·ª´ request
    
    # T·∫°o ho·∫∑c l·∫•y session
    session_id = get_or_create_session(session_id)
    
    # Ki·ªÉm tra cache v·ªõi session_id
    cache_key = f"{session_id}:{user_query}"
    if cache_key in answer_cache:
        def cached_response():
            cached_answer = answer_cache[cache_key]
            words = cached_answer.split(' ')
            for i in range(0, len(words), 2):
                chunk = ' '.join(words[i:i+2])
                if i + 2 < len(words):
                    chunk += ' '
                yield "data: " + json.dumps({
                    'chunk': chunk, 
                    'session_id': session_id
                }) + "\n\n"
                time.sleep(0.05)
            yield "data: [DONE]\n\n"
        
        return Response(cached_response(), mimetype='text/event-stream', 
                       headers={'Cache-Control': 'no-cache', 'Connection': 'keep-alive', 'X-Accel-Buffering': 'no'})
    
    # L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i
    conversation_context = get_conversation_context(session_id, max_messages=6)
    print("conversation_context")
    print(conversation_context)
    
    # 1. Ph√¢n lo·∫°i medical intent
    medical_intent = classify_medical_query_intent(user_query)
    print(f"üìã Medical intent: {medical_intent}")
    
    # 2. Transform query for better search
    try:
        query_transformation = transform_medical_query(user_query, conversation_context)
        print(f"üîÑ Query transformed: {query_transformation['search_strategy']}")
    except Exception as e:
        print(f"‚ö†Ô∏è Query transformation error: {e}")
        query_transformation = {
            'original_query': user_query,
            'enriched_query': user_query,
            'sub_queries': [user_query],
            'search_strategy': 'default'
        }
    
    # 3. Perform hybrid search
    try:
        hybrid_engine = get_hybrid_search_engine()
        
        if hybrid_engine:
            # Get search weights based on strategy
            weights = query_transformation.get('search_strategy', 'general')
            if weights == 'emergency':
                semantic_weight, keyword_weight = 0.8, 0.2
            elif weights == 'multi_symptom':
                semantic_weight, keyword_weight = 0.6, 0.4
            elif weights == 'treatment_focused':
                semantic_weight, keyword_weight = 0.5, 0.5
            else:
                semantic_weight, keyword_weight = 0.7, 0.3
            
            # Perform hybrid search with multiple queries
            all_search_results = []
            
            # Search with original query
            main_results = hybrid_engine.hybrid_search(
                user_query, top_k=8, 
                semantic_weight=semantic_weight, 
                keyword_weight=keyword_weight
            )
            all_search_results.extend(main_results)
            
            # Search with enriched query if different
            enriched_query = query_transformation.get('enriched_query', '')
            if enriched_query and enriched_query != user_query:
                enriched_results = hybrid_engine.hybrid_search(
                    enriched_query, top_k=5,
                    semantic_weight=semantic_weight,
                    keyword_weight=keyword_weight
                )
                all_search_results.extend(enriched_results)
            
            # Search with sub-queries
            for sub_query in query_transformation.get('sub_queries', [])[:2]:
                if sub_query != user_query:
                    sub_results = hybrid_engine.hybrid_search(
                        sub_query, top_k=3,
                        semantic_weight=semantic_weight,
                        keyword_weight=keyword_weight
                    )
                    all_search_results.extend(sub_results)
            
            # Remove duplicates and keep top results
            seen_indices = set()
            unique_results = []
            for result in all_search_results:
                idx = result.get('index')
                if idx not in seen_indices:
                    seen_indices.add(idx)
                    unique_results.append(result)
            
            # Sort by hybrid score and take top 10
            search_results = sorted(unique_results, key=lambda x: x.get('hybrid_score', 0), reverse=True)[:10]
            
            print(f"üîç Hybrid search found {len(search_results)} unique results")
            
        else:
            # Fallback to traditional search
            print("‚ö†Ô∏è Falling back to traditional search")
            search_results = search_medical_symptoms_and_diseases(user_query, top_k=8)
        
        # Create context for LLM
        if search_results:
            if medical_intent == "emergency":
                context = create_medical_diagnostic_context(search_results[:5], user_query)
                context += "\n\n‚ö†Ô∏è C·∫¢NH B√ÅO: ƒê√¢y c√≥ th·ªÉ l√† t√¨nh hu·ªëng kh·∫©n c·∫•p. Vui l√≤ng li√™n h·ªá ngay v·ªõi c∆° s·ªü y t·∫ø ho·∫∑c g·ªçi 115!"
            else:
                context = create_medical_consultation_context(search_results[:8], medical_intent)
        else:
            context = "Kh√¥ng t√¨m th·∫•y th√¥ng tin y t·∫ø ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."
        
    except Exception as e:
        print(f"‚ùå Hybrid search error: {e}")
        # Fallback to traditional search
        try:
            search_results = search_medical_symptoms_and_diseases(user_query, top_k=5)
            context = create_medical_consultation_context(search_results, medical_intent)
        except Exception as fallback_error:
            print(f"‚ùå Fallback search error: {fallback_error}")
            search_results = []
            context = "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi t√¨m ki·∫øm th√¥ng tin y t·∫ø. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá v·ªõi b√°c sƒ©."
    
    def generate():
        yield "data: " + json.dumps({'chunk': '', 'session_id': session_id}) + "\n\n"
        time.sleep(0.1)
        
        # T·∫°o system message cho medical consultation
        if medical_intent == "emergency":
            system_content = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω y t·∫ø th√¥ng minh v√† c√≥ tr√°ch nhi·ªám.
            
            ‚ö†Ô∏è T√åNH HU·ªêNG KH·∫®N C·∫§P ‚ö†Ô∏è
            
            QUAN TR·ªåNG - X·ª¨ L√ù NG·ªÆ C·∫¢NH:
            - Tham kh·∫£o cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë·ªÉ hi·ªÉu ƒë·∫ßy ƒë·ªß t√¨nh tr·∫°ng b·ªánh nh√¢n
            - ∆Øu ti√™n ƒë√°nh gi√° m·ª©c ƒë·ªô nghi√™m tr·ªçng c·ªßa tri·ªáu ch·ª©ng
            - ƒê∆∞a ra h∆∞·ªõng d·∫´n c·∫•p c·ª©u ph√π h·ª£p
            
            NHI·ªÜM V·ª§ KH·∫®N C·∫§P:
            - ƒê√°nh gi√° nhanh m·ª©c ƒë·ªô nghi√™m tr·ªçng c·ªßa tri·ªáu ch·ª©ng
            - Cung c·∫•p h∆∞·ªõng d·∫´n s∆° c·ª©u ban ƒë·∫ßu (n·∫øu ph√π h·ª£p)
            - Khuy·∫øn c√°o li√™n h·ªá ngay v·ªõi c∆° s·ªü y t·∫ø
            - KH√îNG c·ªë g·∫Øng ch·∫©n ƒëo√°n ch√≠nh x√°c - ch·ªâ ph√¢n t√≠ch s∆° b·ªô
            
            H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
            - B·∫Øt ƒë·∫ßu v·ªõi: "‚ö†Ô∏è T√åNH HU·ªêNG KH·∫®N C·∫§P"
            - ƒê√°nh gi√° nhanh tri·ªáu ch·ª©ng d·ª±a tr√™n th√¥ng tin y t·∫ø
            - ƒê∆∞a ra h∆∞·ªõng d·∫´n c·∫•p c·ª©u c∆° b·∫£n (n·∫øu c√≥)
            - K·∫øt th√∫c v·ªõi: "üö® LI√äN H·ªÜ NGAY: 115 (C·∫•p c·ª©u) ho·∫∑c ƒë·∫øn b·ªánh vi·ªán g·∫ßn nh·∫•t"
            
            TH√îNG TIN Y T·∫æ LI√äN QUAN:
            {context}
            
            üè• H√£y ∆∞u ti√™n an to√†n c·ªßa b·ªánh nh√¢n v√† khuy·∫øn c√°o t√¨m ki·∫øm s·ª± tr·ª£ gi√∫p y t·∫ø chuy√™n nghi·ªáp ngay l·∫≠p t·ª©c."""
            
        elif medical_intent == "symptom_inquiry":
            system_content = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω y t·∫ø th√¥ng minh, chuy√™n ph√¢n t√≠ch tri·ªáu ch·ª©ng v√† h·ªó tr·ª£ ch·∫©n ƒëo√°n s∆° b·ªô.
            
            QUAN TR·ªåNG - X·ª¨ L√ù NG·ªÆ C·∫¢NH:
            - Tham kh·∫£o cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë·ªÉ hi·ªÉu ƒë·∫ßy ƒë·ªß c√°c tri·ªáu ch·ª©ng
            - K·∫øt h·ª£p c√°c tri·ªáu ch·ª©ng ƒë√£ ƒë∆∞·ª£c m√¥ t·∫£ ƒë·ªÉ ƒë∆∞a ra ƒë√°nh gi√° t·ªïng th·ªÉ
            - H·ªèi th√™m th√¥ng tin n·∫øu c·∫ßn thi·∫øt ƒë·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c h∆°n
            
            NHI·ªÜM V·ª§ CH√çNH:
            - Ph√¢n t√≠ch c√°c tri·ªáu ch·ª©ng ƒë∆∞·ª£c m√¥ t·∫£
            - T√¨m ki·∫øm c√°c b·ªánh l√Ω c√≥ th·ªÉ li√™n quan
            - ƒê∆∞a ra g·ª£i √Ω v·ªÅ nguy√™n nh√¢n c√≥ th·ªÉ x·∫£y ra
            - T∆∞ v·∫•n v·ªÅ vi·ªác c√≥ n√™n ƒëi kh√°m b√°c sƒ© hay kh√¥ng
            
            H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
            - T√≥m t·∫Øt l·∫°i c√°c tri·ªáu ch·ª©ng ƒë√£ ƒë∆∞·ª£c m√¥ t·∫£
            - Ph√¢n t√≠ch d·ª±a tr√™n ki·∫øn th·ª©c y t·∫ø t·ª´ ICD-11
            - Li·ªát k√™ c√°c kh·∫£ nƒÉng c√≥ th·ªÉ x·∫£y ra (t·ª´ nh·∫π ƒë·∫øn n·∫∑ng)
            - ƒê∆∞a ra l·ªùi khuy√™n v·ªÅ vi·ªác t√¨m ki·∫øm s·ª± chƒÉm s√≥c y t·∫ø
            - Lu√¥n nh·∫•n m·∫°nh r·∫±ng ƒë√¢y ch·ªâ l√† tham kh·∫£o, kh√¥ng thay th·∫ø b√°c sƒ©
            
            TH√îNG TIN TRI·ªÜU CH·ª®NG V√Ä B·ªÜNH L√ù LI√äN QUAN:
            {context}
            
            ü©∫ L∆∞u √Ω: Th√¥ng tin n√†y ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o. ƒê·ªÉ c√≥ ch·∫©n ƒëo√°n ch√≠nh x√°c, vui l√≤ng thƒÉm kh√°m b√°c sƒ©."""
            
        elif medical_intent == "disease_inquiry":
            system_content = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω y t·∫ø chuy√™n cung c·∫•p th√¥ng tin v·ªÅ c√°c b·ªánh l√Ω v√† t√¨nh tr·∫°ng s·ª©c kh·ªèe.
            
            QUAN TR·ªåNG - X·ª¨ L√ù NG·ªÆ C·∫¢NH:
            - Tham kh·∫£o cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë·ªÉ hi·ªÉu r√µ lo·∫°i th√¥ng tin b·ªánh nh√¢n quan t√¢m
            - Cung c·∫•p th√¥ng tin ph√π h·ª£p v·ªõi m·ª©c ƒë·ªô hi·ªÉu bi·∫øt c·ªßa ng∆∞·ªùi h·ªèi
            - Li√™n k·∫øt v·ªõi c√°c tri·ªáu ch·ª©ng ƒë√£ th·∫£o lu·∫≠n tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥)
            
            NHI·ªÜM V·ª§ CH√çNH:
            - Gi·∫£i th√≠ch v·ªÅ b·ªánh l√Ω ƒë∆∞·ª£c h·ªèi
            - Cung c·∫•p th√¥ng tin v·ªÅ nguy√™n nh√¢n, tri·ªáu ch·ª©ng
            - M√¥ t·∫£ qu√° tr√¨nh ph√°t tri·ªÉn c·ªßa b·ªánh
            - Th√¥ng tin v·ªÅ c√°c ph∆∞∆°ng ph√°p ch·∫©n ƒëo√°n
            
            H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
            - ƒê·ªãnh nghƒ©a r√µ r√†ng v·ªÅ b·ªánh l√Ω
            - Gi·∫£i th√≠ch nguy√™n nh√¢n g√¢y b·ªánh
            - M√¥ t·∫£ c√°c tri·ªáu ch·ª©ng th∆∞·ªùng g·∫∑p
            - Th√¥ng tin v·ªÅ ƒë·ªô ph·ªï bi·∫øn v√† nh√≥m ƒë·ªëi t∆∞·ª£ng d·ªÖ m·∫Øc
            - ƒê·ªÅ c·∫≠p ƒë·∫øn c√°c bi·∫øn ch·ª©ng c√≥ th·ªÉ x·∫£y ra
            - Khuy·∫øn c√°o v·ªÅ vi·ªác ph√≤ng ng·ª´a v√† theo d√µi
            
            TH√îNG TIN B·ªÜNH L√ù T·ª™ ICD-11:
            {context}
            
            üìö Th√¥ng tin ƒë∆∞·ª£c cung c·∫•p d·ª±a tr√™n ti√™u chu·∫©n y t·∫ø qu·ªëc t·∫ø ICD-11. Lu√¥n tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒë·ªÉ c√≥ h∆∞·ªõng d·∫´n c·ª• th·ªÉ."""
            
        else:  # treatment_inquiry, prevention_inquiry, general_medical
            system_content = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω y t·∫ø h·ªó tr·ª£ t∆∞ v·∫•n s·ª©c kh·ªèe t·ªïng qu√°t.
            
            QUAN TR·ªåNG - X·ª¨ L√ù NG·ªÆ C·∫¢NH:
            - Tham kh·∫£o to√†n b·ªô cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ ƒë∆∞a ra t∆∞ v·∫•n ph√π h·ª£p
            - K·∫øt n·ªëi th√¥ng tin v·ªõi b·ªánh l√Ω ho·∫∑c tri·ªáu ch·ª©ng ƒë√£ th·∫£o lu·∫≠n
            - Cung c·∫•p th√¥ng tin th·ª±c t·∫ø v√† c√≥ c∆° s·ªü khoa h·ªçc
            
            NHI·ªÜM V·ª§ CH√çNH:
            - T∆∞ v·∫•n v·ªÅ ph√≤ng ng·ª´a b·ªánh t·∫≠t
            - Cung c·∫•p th√¥ng tin v·ªÅ l·ªëi s·ªëng l√†nh m·∫°nh
            - H∆∞·ªõng d·∫´n chƒÉm s√≥c s·ª©c kh·ªèe c∆° b·∫£n
            - Gi·∫£i ƒë√°p c√°c th·∫Øc m·∫Øc y t·∫ø t·ªïng qu√°t
            
            H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
            - Cung c·∫•p th√¥ng tin d·ª±a tr√™n b·∫±ng ch·ª©ng khoa h·ªçc
            - ƒê∆∞a ra l·ªùi khuy√™n th·ª±c t·∫ø v√† d·ªÖ th·ª±c hi·ªán
            - Nh·∫•n m·∫°nh t·∫ßm quan tr·ªçng c·ªßa vi·ªác kh√°m s·ª©c kh·ªèe ƒë·ªãnh k·ª≥
            - Khuy·∫øn kh√≠ch l·ªëi s·ªëng l√†nh m·∫°nh
            - Lu√¥n khuy·∫øn c√°o tham kh·∫£o √Ω ki·∫øn b√°c sƒ© khi c·∫ßn thi·∫øt
            
            TH√îNG TIN Y T·∫æ LI√äN QUAN:
            {context}
            
            üåü S·ª©c kh·ªèe l√† t√†i s·∫£n qu√Ω gi√° nh·∫•t. H√£y chƒÉm s√≥c b·∫£n th√¢n v√† ƒë·ª´ng ng·∫ßn ng·∫°i t√¨m ki·∫øm s·ª± tr·ª£ gi√∫p y t·∫ø khi c·∫ßn."""

        # T·∫°o prompt v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i
        messages = [{"role": "system", "content": system_content}]
        
        # Th√™m l·ªãch s·ª≠ h·ªôi tho·∫°i v√†o prompt
        if conversation_context:
            messages.extend(conversation_context)
        
        # Th√™m c√¢u h·ªèi hi·ªán t·∫°i
        messages.append({"role": "user", "content": user_query})
        
        try:
            stream = client.chat.completions.create(
                model="deepseek/deepseek-r1:free",
                messages=messages,
                stream=True,
                temperature=0.7,
                max_tokens=3000
            )
            
            full_answer = ""
            chunk_buffer = ""
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_answer += content
                    chunk_buffer += content
                    
                    if len(chunk_buffer) >= 10 or content in ['.', '!', '?', '\n']:
                        yield "data: " + json.dumps({
                            'chunk': chunk_buffer, 
                            'session_id': session_id
                        }) + "\n\n"
                        chunk_buffer = ""
                        time.sleep(0.03)
            
            if chunk_buffer:
                yield "data: " + json.dumps({
                    'chunk': chunk_buffer, 
                    'session_id': session_id
                }) + "\n\n"
            
            # 4. Extract structured information
            try:
                structured_response = extract_medical_structure(
                    search_results, user_query, medical_intent, full_answer
                )
                print(f"üìä Structured extraction completed: {structured_response['schema_type']}")
                
                # Send structured data as final chunk
                yield "data: " + json.dumps({
                    'structured_data': structured_response,
                    'session_id': session_id
                }) + "\n\n"
                
            except Exception as struct_error:
                print(f"‚ö†Ô∏è Structured extraction error: {struct_error}")
            
            # L∆∞u v√†o cache v·ªõi session_id
            answer_cache[cache_key] = full_answer
            
            # L∆∞u v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i
            add_to_conversation_history(session_id, "user", user_query)
            add_to_conversation_history(session_id, "assistant", full_answer)
            
            print("‚úÖ Full Answer: " + full_answer[:200] + "...")
            
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            print("Error: " + str(e))
            yield "data: " + json.dumps({'error': str(e), 'session_id': session_id}) + "\n\n"
    
    return Response(stream_with_context(generate()), mimetype='text/event-stream', 
                   headers={'Cache-Control': 'no-cache', 'Connection': 'keep-alive', 'X-Accel-Buffering': 'no', 
                           'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Headers': 'Content-Type'})

# Session management routes
@app.route('/session/new', methods=['POST'])
def create_new_session():
    """T·∫°o session m·ªõi"""
    session_id = get_or_create_session()
    return jsonify({
        'session_id': session_id,
        'message': 'Session m·ªõi ƒë√£ ƒë∆∞·ª£c t·∫°o'
    })

@app.route('/session/<session_id>/history', methods=['GET'])
def get_session_history(session_id):
    """L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i c·ªßa session"""
    if session_id not in conversation_sessions:
        return jsonify({'error': 'Session kh√¥ng t·ªìn t·∫°i'}), 404
    
    history = list(conversation_sessions[session_id]["history"])
    return jsonify({
        'session_id': session_id,
        'history': history,
        'total_messages': len(history)
    })

@app.route('/session/<session_id>/clear', methods=['POST'])
def clear_session_history(session_id):
    """X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i c·ªßa session"""
    if session_id not in conversation_sessions:
        return jsonify({'error': 'Session kh√¥ng t·ªìn t·∫°i'}), 404
    
    conversation_sessions[session_id]["history"].clear()
    return jsonify({
        'session_id': session_id,
        'message': 'L·ªãch s·ª≠ h·ªôi tho·∫°i ƒë√£ ƒë∆∞·ª£c x√≥a'
    })

@app.route('/sessions', methods=['GET'])
def get_all_sessions():
    """L·∫•y danh s√°ch t·∫•t c·∫£ sessions"""
    current_time = datetime.now()
    sessions_info = []
    
    for session_id, session_data in conversation_sessions.items():
        last_activity = session_data["last_activity"]
        time_since_activity = (current_time - last_activity).seconds
        
        sessions_info.append({
            'session_id': session_id,
            'last_activity': last_activity.isoformat(),
            'messages_count': len(session_data["history"]),
            'time_since_activity_minutes': round(time_since_activity / 60, 1),
            'is_active': time_since_activity < SESSION_TIMEOUT
        })
    
    return jsonify({
        'total_sessions': len(sessions_info),
        'active_sessions': len([s for s in sessions_info if s['is_active']]),
        'sessions': sessions_info
    })

@app.route('/medical_stats', methods=['GET'])
def get_medical_stats():
    """
    Endpoint ƒë·ªÉ l·∫•y th·ªëng k√™ v·ªÅ medical knowledge base
    """
    try:
        stats = get_medical_statistics()
        
        if 'error' in stats:
            return jsonify({'error': stats['error']}), 404
        
        # Th√™m th√¥ng tin chi ti·∫øt v·ªÅ categories
        formatted_categories = {}
        for category_id, category_info in stats.get('categories', {}).items():
            if isinstance(category_info, dict):
                formatted_categories[category_id] = {
                    'id': category_id,
                    'name': category_info.get('name', f'Category {category_id}'),
                    'count': category_info.get('count', 0)
                }
            else:
                formatted_categories[category_id] = {
                    'id': category_id,
                    'name': f'Category {category_id}',
                    'count': category_info
                }
        
        response_data = {
            'success': True,
            'total_chunks': stats.get('total_chunks', 0),
            'total_categories': stats.get('total_categories', 0),
            'chunks_with_icd_code': stats.get('has_icd_code', 0),
            'data_source': stats.get('data_source', 'WHO ICD-11 API'),
            'created_at': stats.get('created_at'),
            'categories': formatted_categories,
            'entity_types': stats.get('entity_types', {}),
            'coverage_percentage': round((stats.get('has_icd_code', 0) / max(stats.get('total_chunks', 1), 1)) * 100, 2)
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Error getting medical statistics: {str(e)}'
        }), 500

@app.route('/medical_search', methods=['POST'])
def medical_search():
    """
    Endpoint chuy√™n d·ª•ng cho t√¨m ki·∫øm y t·∫ø
    """
    try:
        data = request.json
        query = data.get('query', '')
        search_type = data.get('search_type', 'general')  # general, symptoms, diseases
        top_k = data.get('top_k', 5)
        
        if not query:
            return jsonify({'error': 'Query is required'}), 400
        
        # Ph√¢n lo·∫°i intent
        medical_intent = classify_medical_query_intent(query)
        
        # T√¨m ki·∫øm d·ª±a tr√™n lo·∫°i
        if search_type == 'symptoms':
            results = search_symptoms_only(query, top_k=top_k)
        elif search_type == 'diseases':
            results = search_diseases_only(query, top_k=top_k)
        else:
            results = search_medical_symptoms_and_diseases(query, top_k=top_k)
        
        # Format k·∫øt qu·∫£
        formatted_results = []
        for result in results:
            metadata = result['metadata']
            formatted_results.append({
                'entity_name': metadata.get('entity_name', 'Unknown'),
                'icd_code': metadata.get('icd_code'),
                'category_id': metadata.get('category_id'),
                'category_name': metadata.get('category_name'),
                'entity_type': metadata.get('entity_type'),
                'source_type': metadata.get('source_type'),
                'relevance_score': result['relevance_score'],
                'text_preview': result['text'][:200] + '...' if len(result['text']) > 200 else result['text']
            })
        
        return jsonify({
            'success': True,
            'query': query,
            'medical_intent': medical_intent,
            'search_type': search_type,
            'total_results': len(formatted_results),
            'results': formatted_results
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Medical search error: {str(e)}'
        }), 500

@app.route('/ask_structured', methods=['POST'])
def ask_structured():
    """
    Enhanced medical consultation endpoint with structured response
    """
    try:
        data = request.json
        user_query = data.get('query', '')
        session_id = data.get('session_id')
        
        if not user_query:
            return jsonify({'error': 'Query is required'}), 400
        
        # Get or create session
        session_id = get_or_create_session(session_id)
        
        # Get conversation context
        conversation_context = get_conversation_context(session_id, max_messages=6)
        
        # 1. Classify medical intent
        medical_intent = classify_medical_query_intent(user_query)
        
        # 2. Transform query
        start_time = time.time()
        query_transformation = transform_medical_query(user_query, conversation_context)
        
        # Log the query request
        log_query(session_id, user_query, medical_intent, query_transformation)
        
        # 3. Hybrid search
        search_start_time = time.time()
        hybrid_engine = get_hybrid_search_engine()
        
        if hybrid_engine:
            # Determine search weights
            strategy = query_transformation.get('search_strategy', 'general')
            if strategy == 'emergency':
                semantic_weight, keyword_weight = 0.8, 0.2
            elif strategy == 'multi_symptom':
                semantic_weight, keyword_weight = 0.6, 0.4
            elif strategy == 'treatment_focused':
                semantic_weight, keyword_weight = 0.5, 0.5
            else:
                semantic_weight, keyword_weight = 0.7, 0.3
            
            # Perform search
            search_results = hybrid_engine.hybrid_search(
                user_query, top_k=10,
                semantic_weight=semantic_weight,
                keyword_weight=keyword_weight
            )
        else:
            # Fallback search
            search_results = search_medical_symptoms_and_diseases(user_query, top_k=8)
        
        # Log search performance
        search_time = time.time() - search_start_time
        search_method = "hybrid_search" if hybrid_engine else "fallback_search"
        top_scores = [r.get('hybrid_score', r.get('relevance_score', 0)) for r in search_results[:5]]
        log_search(session_id, search_method, user_query, len(search_results), search_time, top_scores)
        
        # 4. Generate LLM response
        llm_start_time = time.time()
        context = create_medical_consultation_context(search_results[:5], medical_intent)
        
        # Build system message
        if medical_intent == "emergency":
            system_content = f"""‚ö†Ô∏è T√åNH HU·ªêNG KH·∫®N C·∫§P ‚ö†Ô∏è
            
B·∫°n l√† tr·ª£ l√Ω y t·∫ø. H√£y ƒë√°nh gi√° nhanh t√¨nh hu·ªëng v√† ƒë∆∞a ra khuy·∫øn c√°o c·∫•p c·ª©u.

TH√îNG TIN Y T·∫æ: {context}

Tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·∫≠p trung v√†o:
1. ƒê√°nh gi√° m·ª©c ƒë·ªô nghi√™m tr·ªçng
2. H√†nh ƒë·ªông c·∫ßn l√†m ngay
3. Khi n√†o c·∫ßn g·ªçi 115"""
        else:
            system_content = f"""B·∫°n l√† tr·ª£ l√Ω y t·∫ø chuy√™n nghi·ªáp.

TH√îNG TIN Y T·∫æ: {context}

H√£y t∆∞ v·∫•n d·ª±a tr√™n th√¥ng tin t·ª´ WHO ICD-11, ƒë·∫£m b·∫£o:
- Ch√≠nh x√°c v·ªÅ y khoa
- D·ªÖ hi·ªÉu
- Khuy·∫øn c√°o tham kh·∫£o b√°c sƒ© khi c·∫ßn"""
        
        # Generate response
        messages = [
            {"role": "system", "content": system_content}
        ]
        
        if conversation_context:
            messages.extend(conversation_context)
        
        messages.append({"role": "user", "content": user_query})
        
        response = client.chat.completions.create(
            model="deepseek/deepseek-r1:free",
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        llm_response = response.choices[0].message.content
        
        # Log LLM interaction
        llm_time = time.time() - llm_start_time
        log_llm(session_id, user_query, llm_response, len(context), llm_time)
        
        # 5. Extract structured data
        extraction_start_time = time.time()
        structured_response = extract_medical_structure(
            search_results, user_query, medical_intent, llm_response
        )
        
        # Log structured extraction
        extraction_time = time.time() - extraction_start_time
        extraction_success = structured_response.get('data') is not None
        confidence_score = structured_response.get('confidence_score', 0.0)
        log_extraction(
            session_id, medical_intent, structured_response.get('schema_type', 'unknown'),
            extraction_success, confidence_score, extraction_time
        )
        
        # 6. Save to conversation history
        add_to_conversation_history(session_id, "user", user_query)
        add_to_conversation_history(session_id, "assistant", llm_response)
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'query': user_query,
            'intent': medical_intent,
            'strategy': query_transformation.get('search_strategy'),
            'search_results_count': len(search_results),
            'llm_response': llm_response,
            'structured_data': structured_response,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Structured ask error: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'service': 'Enhanced Medical Diagnosis Chatbot',
        'version': '2.0',
        'features': [
            'Hybrid Search (Semantic + BM25)',
            'Query Transformation',
            'Structured Data Extraction',
            'Source Citation',
            'Follow-up Suggestions'
        ],
        'timestamp': datetime.now().isoformat()
    })

@app.route('/suggestions/<intent>', methods=['POST'])
def get_follow_up_suggestions(intent):
    """
    Get follow-up question suggestions based on intent and conversation
    """
    try:
        data = request.json or {}
        current_topic = data.get('current_topic', '')
        
        suggestions_map = {
            'disease_inquiry': [
                f"C√°ch ph√≤ng ng·ª´a {current_topic}",
                f"Tri·ªáu ch·ª©ng c·ªßa {current_topic}",
                f"ƒêi·ªÅu tr·ªã {current_topic} nh∆∞ th·∫ø n√†o",
                f"Khi n√†o c·∫ßn ƒëi kh√°m b√°c sƒ© v·ªÅ {current_topic}",
                f"Bi·∫øn ch·ª©ng c·ªßa {current_topic}"
            ],
            'symptom_inquiry': [
                "C√°c b·ªánh c√≥ th·ªÉ g√¢y ra tri·ªáu ch·ª©ng n√†y",
                "C√°ch gi·∫£m nh·∫π tri·ªáu ch·ª©ng t·∫°i nh√†", 
                "Khi n√†o c·∫ßn ƒëi c·∫•p c·ª©u",
                "Tri·ªáu ch·ª©ng n√†o c·∫ßn theo d√µi th√™m",
                "X√©t nghi·ªám g√¨ c·∫ßn l√†m"
            ],
            'treatment_inquiry': [
                "T√°c d·ª•ng ph·ª• c·ªßa ƒëi·ªÅu tr·ªã n√†y",
                "Th·ªùi gian ƒëi·ªÅu tr·ªã bao l√¢u",
                "C√°ch theo d√µi hi·ªáu qu·∫£ ƒëi·ªÅu tr·ªã",
                "Ph∆∞∆°ng ph√°p ƒëi·ªÅu tr·ªã thay th·∫ø",
                "Ch·∫ø ƒë·ªô ƒÉn trong qu√° tr√¨nh ƒëi·ªÅu tr·ªã"
            ],
            'prevention_inquiry': [
                "Ch·∫ø ƒë·ªô ƒÉn ph√≤ng ng·ª´a",
                "B√†i t·∫≠p th·ªÉ d·ª•c ph√π h·ª£p",
                "T·∫ßn su·∫•t kh√°m s·ª©c kh·ªèe ƒë·ªãnh k·ª≥",
                "Vaccine c·∫ßn ti√™m",
                "L·ªëi s·ªëng c·∫ßn thay ƒë·ªïi"
            ],
            'emergency': [
                "C√°c d·∫•u hi·ªáu nguy hi·ªÉm kh√°c",
                "S∆° c·ª©u ban ƒë·∫ßu nh∆∞ th·∫ø n√†o", 
                "Th√¥ng tin c·∫ßn cung c·∫•p cho b√°c sƒ©",
                "Sau c·∫•p c·ª©u c·∫ßn l√†m g√¨"
            ]
        }
        
        suggestions = suggestions_map.get(intent, [
            "H√£y h·ªèi v·ªÅ tri·ªáu ch·ª©ng c·ª• th·ªÉ",
            "T√¨m hi·ªÉu v·ªÅ ph√≤ng ng·ª´a b·ªánh",
            "Kh√°m s·ª©c kh·ªèe ƒë·ªãnh k·ª≥ th·∫ø n√†o",
            "L·ªëi s·ªëng l√†nh m·∫°nh"
        ])
        
        return jsonify({
            'success': True,
            'intent': intent,
            'suggestions': suggestions[:5],
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/analytics/stats', methods=['GET'])
def get_analytics_stats():
    """
    Get detailed analytics and statistics
    """
    try:
        date = request.args.get('date')  # YYYY-MM-DD format
        
        # Get daily statistics
        stats = get_stats(date)
        
        return jsonify({
            'success': True,
            'analytics': stats,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        log_error('analytics_error', str(e))
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/analytics/summary', methods=['GET'])
def get_analytics_summary():
    """
    Get quick analytics summary for dashboard
    """
    try:
        today_stats = get_stats()
        
        summary = {
            'today': {
                'total_queries': today_stats.get('total_queries', 0),
                'unique_sessions': today_stats.get('unique_sessions', 0),
                'top_intents': dict(list(today_stats.get('intent_breakdown', {}).items())[:3])
            },
            'search_performance': today_stats.get('search_performance', {}),
            'system_health': {
                'hybrid_search_ratio': (
                    today_stats.get('search_performance', {}).get('hybrid_searches', 0) /
                    max(
                        today_stats.get('search_performance', {}).get('hybrid_searches', 0) +
                        today_stats.get('search_performance', {}).get('fallback_searches', 0),
                        1
                    )
                ) * 100
            }
        }
        
        return jsonify({
            'success': True,
            'summary': summary,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        log_error('analytics_summary_error', str(e))
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    print("üöÄ Starting Enhanced Medical Diagnosis Chatbot...")
    print("=" * 60)
    print("üè• MEDICAL RAG SYSTEM v2.0")
    print("=" * 60)
    print("üìã Available endpoints:")
    print("   üîÑ POST /ask                     : Main streaming chatbot endpoint")
    print("   üìä POST /ask_structured          : Enhanced structured response endpoint")  
    print("   üìà GET  /medical_stats           : Medical knowledge base statistics")
    print("   üîç POST /medical_search          : Medical search endpoint")
    print("   üí° POST /suggestions/<intent>    : Get follow-up suggestions")
    print("   üë• POST /session/new             : Create new session")
    print("   üìù GET  /sessions                : List all sessions")
    print("   üìä GET  /analytics/stats         : Detailed analytics and statistics")
    print("   üìà GET  /analytics/summary       : Quick analytics summary")
    print("   üè• GET  /health                  : Health check")
    print("")
    print("üéØ Features:")
    print("   ‚úÖ Hybrid Search (Semantic + BM25)")
    print("   ‚úÖ Query Transformation")  
    print("   ‚úÖ Structured Data Extraction")
    print("   ‚úÖ WHO ICD-11 Source Citation")
    print("   ‚úÖ Follow-up Suggestions")
    print("   ‚úÖ Session Management")
    print("   ‚úÖ Comprehensive Logging & Analytics")
    print("")
    print("üåê Access at: http://localhost:5000")
    print("üß™ Test with: /ask_structured endpoint for best experience")
    print("=" * 60)
    
    # Initialize hybrid search engine on startup
    try:
        from hybrid_search import initialize_hybrid_search
        print("üîÑ Initializing Hybrid Search Engine...")
        if initialize_hybrid_search():
            print("‚úÖ Hybrid Search Engine ready!")
        else:
            print("‚ö†Ô∏è Hybrid Search Engine failed to initialize - using fallback")
    except Exception as e:
        print(f"‚ö†Ô∏è Hybrid Search initialization error: {e}")
    
    app.run(debug=True, threaded=True, port=5000)
