# üß† H∆∞·ªõng d·∫´n Setup RAG (Retrieval-Augmented Generation) cho AI Ch·∫©n ƒëo√°n Y t·∫ø

## üìã T·ªïng quan

RAG system k·∫øt h·ª£p **Retrieval** (t√¨m ki·∫øm th√¥ng tin) v·ªõi **Generation** (t·∫°o c√¢u tr·∫£ l·ªùi) ƒë·ªÉ cung c·∫•p ch·∫©n ƒëo√°n y t·∫ø ch√≠nh x√°c v√† c√≥ cƒÉn c·ª©.

### üèóÔ∏è Ki·∫øn tr√∫c RAG

```
User Query ‚Üí [Embedding] ‚Üí [Vector Search] ‚Üí [Relevant Docs] ‚Üí [LLM + Context] ‚Üí [Response]
```

## üöÄ B∆∞·ªõc 1: Setup Environment

### 1.1. T·∫°o Virtual Environment

```bash
python -m venv rag_env
source rag_env/bin/activate  # Linux/Mac
# rag_env\Scripts\activate   # Windows

pip install -r rag_requirements.txt
```

### 1.2. Download Models

```bash
# Download Vietnamese sentence transformer
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('keepitreal/vietnamese-sbert')"

# Download SpaCy models
python -m spacy download en_core_web_sm
python -m spacy download vi_core_news_sm
```

## üìä B∆∞·ªõc 2: Thu th·∫≠p D·ªØ li·ªáu

### 2.1. Ch·∫°y Data Collection

```bash
python data_collection_guide.py
```

### 2.2. Ngu·ªìn d·ªØ li·ªáu ƒë∆∞·ª£c khuy·∫øn ngh·ªã:

#### **üáªüá≥ D·ªØ li·ªáu Vi·ªát Nam:**

- **ICD-10 Vi·ªát Nam** t·ª´ B·ªô Y t·∫ø
- **H∆∞·ªõng d·∫´n ch·∫©n ƒëo√°n** t·ª´ b·ªánh vi·ªán l·ªõn
- **Danh m·ª•c thu·ªëc** t·ª´ C·ª•c Qu·∫£n l√Ω D∆∞·ª£c

#### **üåç D·ªØ li·ªáu Qu·ªëc t·∫ø:**

- **SNOMED CT** - Thu·∫≠t ng·ªØ y t·∫ø chu·∫©n
- **MedlinePlus** - Th√¥ng tin y t·∫ø tin c·∫≠y
- **Mayo Clinic** - C∆° s·ªü d·ªØ li·ªáu tri·ªáu ch·ª©ng
- **PubMed** - B√†i b√°o nghi√™n c·ª©u y h·ªçc

### 2.3. C·∫•u tr√∫c d·ªØ li·ªáu m·∫´u:

```json
{
  "diseases": [
    {
      "name": "C·∫£m c√∫m",
      "icd_code": "J11",
      "symptoms": ["s·ªët", "ho", "ƒëau ƒë·∫ßu"],
      "treatment": "Ngh·ªâ ng∆°i, u·ªëng thu·ªëc h·∫° s·ªët",
      "severity": "mild",
      "duration": "7-10 ng√†y"
    }
  ],
  "symptoms": [
    {
      "name": "s·ªët",
      "description": "Nhi·ªát ƒë·ªô c∆° th·ªÉ tƒÉng cao",
      "possible_diseases": ["c√∫m", "COVID-19", "nhi·ªÖm khu·∫©n"],
      "questions": ["S·ªët bao nhi·ªÅu ƒë·ªô?", "S·ªët t·ª´ khi n√†o?"]
    }
  ]
}
```

## üîß B∆∞·ªõc 3: X·ª≠ l√Ω D·ªØ li·ªáu

### 3.1. Ch·∫°y Data Processing

```bash
python rag_data_preparation.py
```

### 3.2. K·∫øt qu·∫£ sau x·ª≠ l√Ω:

- `medical_knowledge_base/documents.json` - Documents ƒë√£ x·ª≠ l√Ω
- `medical_knowledge_base/embeddings.npy` - Vector embeddings
- `medical_knowledge_base/faiss_index.bin` - Search index

## üîç B∆∞·ªõc 4: Setup RAG System

### 4.1. T·∫°o RAG Flask API

```python
# rag_api.py
from flask import Flask, request, jsonify
from flask_cors import CORS
from rag_data_preparation import MedicalRAGDataProcessor
import openai  # ho·∫∑c d√πng local LLM nh∆∞ llama-cpp-python

app = Flask(__name__)
CORS(app)

# Load RAG system
processor = MedicalRAGDataProcessor()
processor.load_knowledge_base("medical_knowledge_base")

# Setup LLM (c√≥ th·ªÉ d√πng OpenAI, Anthropic, ho·∫∑c local model)
openai.api_key = "your-api-key"

@app.route('/diagnosis', methods=['POST'])
def diagnose():
    try:
        data = request.json

        # Extract user info v√† symptoms
        user_profile = data.get('userProfile', {})
        symptoms = data.get('symptoms', [])

        # T·∫°o query t·ª´ symptoms
        symptom_text = ", ".join([s.get('name', '') for s in symptoms])
        query = f"Tri·ªáu ch·ª©ng: {symptom_text}. Tu·ªïi: {user_profile.get('age', 'N/A')}. Gi·ªõi t√≠nh: {user_profile.get('gender', 'N/A')}"

        # Retrieve relevant documents
        relevant_docs = processor.search_similar_documents(query, top_k=5)

        # Prepare context for LLM
        context = "\n\n".join([doc.content for doc, score in relevant_docs])

        # Generate diagnosis using LLM
        diagnosis_response = generate_diagnosis(query, context, user_profile, symptoms)

        return jsonify(diagnosis_response)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

def generate_diagnosis(query, context, user_profile, symptoms):
    """Generate diagnosis using LLM v·ªõi retrieved context"""

    prompt = f"""
    B·∫°n l√† m·ªôt AI y t·∫ø h·ªó tr·ª£ ch·∫©n ƒëo√°n. D·ª±a tr√™n th√¥ng tin sau, h√£y ƒë∆∞a ra ch·∫©n ƒëo√°n c√≥ th·ªÉ v√† khuy·∫øn ngh·ªã:

    TH√îNG TIN B·ªÜNH NH√ÇN:
    {query}

    TH√îNG TIN Y T·∫æ THAM KH·∫¢O:
    {context}

    H√£y tr·∫£ l·ªùi theo format JSON:
    {{
        "results": [
            {{
                "diseaseName": "T√™n b·ªánh",
                "probability": 0.8,
                "description": "M√¥ t·∫£ b·ªánh",
                "severity": "MILD/MODERATE/SEVERE",
                "matchedSymptoms": ["tri·ªáu ch·ª©ng kh·ªõp"],
                "recommendedSpecialty": "Chuy√™n khoa khuy·∫øn ngh·ªã"
            }}
        ],
        "recommendations": ["Khuy·∫øn ngh·ªã 1", "Khuy·∫øn ngh·ªã 2"],
        "urgencyLevel": "LOW/MEDIUM/HIGH/CRITICAL",
        "disclaimerMessage": "K·∫øt qu·∫£ ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o"
    }}
    """

    # G·ªçi LLM (OpenAI GPT, Claude, ho·∫∑c local model)
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    # Parse response
    import json
    try:
        result = json.loads(response.choices[0].message.content)
        return result
    except:
        # Fallback response
        return {
            "results": [{"diseaseName": "C·∫ßn th√™m th√¥ng tin", "probability": 0.5}],
            "recommendations": ["N√™n tham kh·∫£o √Ω ki·∫øn b√°c sƒ©"],
            "urgencyLevel": "MEDIUM"
        }

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

### 4.2. Alternative: S·ª≠ d·ª•ng Local LLM

```python
# S·ª≠ d·ª•ng llama-cpp-python cho local LLM
from llama_cpp import Llama

# Load local model (v√≠ d·ª•: Code Llama, Mistral, Zephyr)
llm = Llama(model_path="path/to/model.gguf", n_ctx=4096)

def generate_with_local_llm(prompt):
    output = llm(prompt, max_tokens=1000, temperature=0.3)
    return output['choices'][0]['text']
```

## üéØ B∆∞·ªõc 5: Testing & Validation

### 5.1. Test RAG System

```python
# test_rag.py
from rag_data_preparation import MedicalRAGDataProcessor

processor = MedicalRAGDataProcessor()
processor.load_knowledge_base("medical_knowledge_base")

# Test queries
test_queries = [
    "ƒëau ƒë·∫ßu v√† s·ªët",
    "ho khan k√©o d√†i",
    "ƒëau b·ª•ng v√† bu·ªìn n√¥n",
    "m·ªát m·ªèi v√† kh√≥ th·ªü"
]

for query in test_queries:
    print(f"\nQuery: {query}")
    results = processor.search_similar_documents(query, top_k=3)
    for doc, score in results:
        print(f"  Score: {score:.3f} - {doc.title}")
```

### 5.2. Evaluate RAG Performance

```python
# Metrics ƒë·ªÉ ƒë√°nh gi√°:
# - Precision@K: ƒê·ªô ch√≠nh x√°c c·ªßa top-K results
# - Recall@K: T·ª∑ l·ªá relevant docs ƒë∆∞·ª£c retrieve
# - MRR (Mean Reciprocal Rank): V·ªã tr√≠ c·ªßa relevant doc ƒë·∫ßu ti√™n
```

## üîß B∆∞·ªõc 6: Integration v·ªõi Backend

### 6.1. Start Flask RAG API

```bash
python rag_api.py
# API s·∫Ω ch·∫°y t·∫°i http://localhost:5000
```

### 6.2. Test Integration

```bash
curl -X POST http://localhost:5000/diagnosis \
  -H "Content-Type: application/json" \
  -d '{
    "sessionId": "test-session",
    "userProfile": {"age": 30, "gender": "MALE"},
    "symptoms": [{"name": "ƒëau ƒë·∫ßu", "severity": 7}]
  }'
```

### 6.3. Backend Spring Boot s·∫Ω g·ªçi API n√†y

- URL: `http://localhost:5000/diagnosis`
- API Key authentication
- Structured request/response format

## üìà B∆∞·ªõc 7: Optimization & Scaling

### 7.1. Performance Optimization

```python
# Caching v·ªõi Redis
import redis
r = redis.Redis(host='localhost', port=6379, db=0)

def cached_search(query):
    cache_key = f"search:{hash(query)}"
    cached_result = r.get(cache_key)
    if cached_result:
        return json.loads(cached_result)

    result = processor.search_similar_documents(query)
    r.setex(cache_key, 3600, json.dumps(result))  # Cache 1 hour
    return result
```

### 7.2. Model Updates

```python
# ƒê·ªãnh k·ª≥ update knowledge base
def update_knowledge_base():
    # Re-crawl data
    # Re-process documents
    # Rebuild FAISS index
    # Hot-swap in production
    pass
```

### 7.3. Monitoring

```python
# Log t·∫•t c·∫£ queries v√† responses
import logging
import wandb  # Weights & Biases for ML monitoring

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route('/diagnosis', methods=['POST'])
def diagnose():
    start_time = time.time()

    # ... processing ...

    # Log metrics
    response_time = time.time() - start_time
    logger.info(f"Query processed in {response_time:.2f}s")

    # Track with W&B
    wandb.log({
        "response_time": response_time,
        "query_length": len(query),
        "num_symptoms": len(symptoms)
    })
```

## üöÄ Production Deployment

### Docker Setup

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY rag_requirements.txt .
RUN pip install -r rag_requirements.txt

COPY . .
EXPOSE 5000

CMD ["python", "rag_api.py"]
```

### Docker Compose

```yaml
# docker-compose.yml
version: "3.8"
services:
  rag-api:
    build: .
    ports:
      - "5000:5000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./medical_knowledge_base:/app/medical_knowledge_base

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

## üìä Data Quality & Legal Considerations

### ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:

1. **B·∫£n quy·ªÅn & Ph√°p l√Ω**

   - Tu√¢n th·ªß robots.txt khi scraping
   - Xin ph√©p s·ª≠ d·ª•ng d·ªØ li·ªáu y t·∫ø
   - Tu√¢n th·ªß GDPR, HIPAA

2. **Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu**

   - Validate t·ª´ nhi·ªÅu ngu·ªìn
   - Ki·ªÉm tra b·ªüi chuy√™n gia y t·∫ø
   - C·∫≠p nh·∫≠t ƒë·ªãnh k·ª≥

3. **Disclaimer**
   - Lu√¥n c·∫£nh b√°o: "Ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o"
   - Khuy·∫øn kh√≠ch g·∫∑p b√°c sƒ©
   - Kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n y t·∫ø

## üéì T√†i nguy√™n h·ªçc th√™m

- [LangChain Documentation](https://python.langchain.com/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Sentence Transformers](https://www.sbert.net/)
- [Medical NLP with spaCy](https://spacy.io/universe/project/medspacy)

## üîß Next Steps

1. ‚úÖ **Implement RAG system** nh∆∞ h∆∞·ªõng d·∫´n tr√™n
2. ‚úÖ **Test v·ªõi d·ªØ li·ªáu th·∫≠t**
3. ‚úÖ **Fine-tune embedding model** v·ªõi medical domain
4. ‚úÖ **Setup monitoring & logging**
5. ‚úÖ **Deploy to production**

Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi RAG system! üöÄüè•

